# pytorch_attention
Pytorch implementation of Bahdanau attention with inspiration from several wonderful resources:
* [The Annotated Encoder Decoder](https://bastings.github.io/annotated_encoder_decoder/)
* [Neural machine translation with attention](https://www.tensorflow.org/tutorials/text/nmt_with_attention)
* [Pytorch Seq2Seq Tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) 
* [Attention? Attention!](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)

# Usage

1) Download and extract english-french translation data [here](https://download.pytorch.org/tutorial/data.zip).
2) ```python3 train.py```
